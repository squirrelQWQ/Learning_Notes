参考视频：李宏毅机器学习2023 spring

参考书籍：周志华《机器学习》



## 理论

> 机器学习就是让计算机自己找出一个函数

### 名词

泛化误差：generalization error，模型在新样本上的误差称为泛化误差

- 我的理解：泛化在这里表示该参数是模型在从未试验过的数据上运行的结果
- 泛化：以旧判新，由已知的判未知的

过拟合：overfitting

欠拟合：underfitting





### 回归

### 分类

### 数学

P(A|B)：表示在B发生的条件下A发生的概率



李宏毅：机器学习分三大步

1. 设定范围（选择模型，比如CNN、Transformer等）
2. 设定标准（损失函数）
3. 达成目标（优化函数）

##### 模型

> 李宏毅：模型就是要找的函数范围（在此范围内找到合适的目标函数）

模型就是一系列候选函数的集合，比如：CNN、Transformer等



##### 损失函数

> 李宏毅：损失函数给定了衡量函数好坏的标准（指导我们在目标函数集合中找到最合适的）

评价一个函数好坏的方法：

- 有正确标定的数据集时：直接用此数据输入函数中，看结果和正确值的差距
- 没有正确标定的数据集时：相似的样本应该得到相似的输出

也可以理解为给定一个衡量函数好坏的标准



找到更好的函数

> 李宏毅：根据损失函数找到目前最好的函数后，还有对其进行优化（实际上函数是有很多很多参数的，大型的模型可能有上亿的参数，在写代码过程中手动设置的参数叫“超参数”）

##### 梯度下降

##### 反向传播



生成式AI：其输出结果不再是一个简单的数字或概率，而是一个有结构的东西（图像、文字、视频等）



## 实践

### 显卡、显卡驱动、CUDA、pytorch

显卡：是硬件，也就是GPU

显卡驱动：显卡厂商提供的控制显卡的接口软件

CUDA：是 Nvidia GPU 的通用计算平台

- 我的理解：CUDA就是英伟达提供的用来控制GPU更好的并行运算的一个软件
  - （类似操作系统控制CPU进行并发）

pytorch：



> 这几个玩意儿之间是有版本依赖关系的，所以需要一步步的确定本机的版本

依赖关系：显卡 ==> 显卡驱动 ==> CUDA ==> pytorch

1. 查看显卡版本：任务管理器 -> 性能 -> GPU

![image-20230610100049851](深度学习.assets/image-20230610100049851.png)

2. 查看驱动和CUDA的版本：nvidia-smi

![](深度学习.assets/image-20230613103913764.png)

3. 安装对应版本pytorch 
    官网： https://pytorch.org/

  ![image-20230618162951661](深度学习.assets/image-20230618162951661.png)

由图可知目前官网推荐CUDA版本是11.7和11.8，而我电脑是11.6所以我决定升级以下

4. 如何升级？

首先显卡硬件是不可以改变的，那么就可以考虑升级驱动，或直接升级CUDA

- 原理就是无论是驱动或者CUDA都是向后兼容的，至少较近的几个版本兼容

英伟达官网：https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html

![image-20230613113740950](深度学习.assets/image-20230613113740950.png)

由官网可知，我机器的驱动版本支持11.8的CUDA故直接安装11.8版本CUDA即可

我选择的是conda安装，所以复制命令打开anaconda prompt进入创建好的环境中

![image-20230618163203802](深度学习.assets/image-20230618163203802.png)

anaconda会自动扫描需要下载的所有包，选择y静等下载完成

验证安装结果：pip list

![image-20230618164945180](深度学习.assets/image-20230618164945180.png)

列表中由torch表示安装完成，当然也可以调用python，输入import torch来验证，只要不报错就是安装成功

### Anaconda

一个包管理工具

其提供了一个命令行交互界面：anaconda prompt

![image-20230618160323375](深度学习.assets/image-20230618160323375.png)

#### 命令

> 【】表示括号内的内容由用户自己决定

查看当前conda版本：conda --version

查看环境：conda info --env

创建环境：conda create -n 【name】 python=【3.10】

删除环境：conda remove -n 【name】 --all

激活环境：conda activate 【name】

退出环境：conda deactivate

修改环境名称： conda create --name 【新名字】 --clone 【旧名字】

​							conda remove --name 【旧名字】 --all

### jupyter

一个web应用，简单来说和IDEA、PyCharm 类似只不过它是依赖web的应用，IDEA叫桌面应用



### pytorch

#### 常用工具

dataset类

dataloder类

##### tensorboard类

运行后要查看tensorboard，直接在终端启用conda环境，再运行下面语句：

```powershell
 tensorboard --logdir="你的logs目录"
```

运行结果会给出URL，复制到浏览器即可查看

运行结果会给出URL，复制到浏览器即可查看

一个用图表形式表现训练过程中的效果变化



##### transforms

（一个处理图像的工具库）

比如将image转换为tensor



##### 卷积

![](深度学习.assets/Conve2d输入和输出参数计算公式.png)

上图是pytorch官方文档给出的Conv2d（2维卷积）输入参数和输出结果的计算公式，

其中：$（N ， C_{in} , H_{in} , W_{in}）$的含义如下

- N：表示batchsize，即：一个批次含图片数量
- $C_{in}$：表示输入图像的通道数（channel）
- $H_{in}$：输入图像的高度
- $W_{in}$：输入图像的宽度

Output公式中dilation是空洞卷积的参数，如果不是空洞卷积则为1



```python
Conv2d(3,32,5,padding=2)
'''
	输入图像为3通道，
	输出结果为32通道
	5x5的卷积核（同图像大小一样，宽高相同简写为5，也可以用元组）
	padding为2（就是图像周围填充22像素）
	stride取默认值1
'''
Conv2d(3,32,5,1,2)	# 这样写和上面的效果等价
```



### 神经网络

#### 卷积层

#### 最大池化

#### 非线性激活

#### 线性层

#### 损失函数和反向传播

损失函数就是评估输出结果和目标结果之间的差距（loss越小越好），为更新输出提供参考依据（反向传播）

