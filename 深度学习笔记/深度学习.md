参考视频：李宏毅机器学习2023 spring

参考书籍：周志华《机器学习》



## 理论

> 机器学习就是让计算机自己找出一个函数

### 名词

**泛化误差**：generalization error，模型在新样本上的误差称为泛化误差

- 我的理解：泛化在这里表示该参数是模型在从未试验过的数据上运行的结果
- 泛化：以旧判新，由已知的判未知的

**过拟合**：overfitting

**欠拟合**：underfitting

**参数**：模型的参数（大型模型的参数能上亿）可通过优化算法来学习

**超参数**：定义模型结构或优化策略的参数（由程序员来设定的）

**batch_size**：一次处理的数据量（如果每次只处理一张图片这样会很慢，故多张图片组成一个批次，每次处理一批数据这样更快）

**Feature Selection**：特征选择，你所选择的特征并不都有用，有些甚至会起反作用（噪声）所以需要对特征进行选择

**集成学习**：







**神经网络如何分层？**

李沐：这个得看分层的依据，一般来说还是以有无参数来计算，比如多层感知机（MLP）中：求和+激活 为一层



### 回归

### 分类

### 数学

P(A|B)：表示在B发生的条件下A发生的概率



李宏毅：机器学习分三大步

1. 设定范围（选择模型，比如CNN、Transformer等）
2. 设定标准（损失函数）
3. 达成目标（优化函数）

##### 模型

> 李宏毅：模型就是要找的函数范围（在此范围内找到合适的目标函数）

模型就是一系列候选函数的集合，比如：CNN、Transformer等



##### 损失函数

> 李宏毅：损失函数给定了衡量函数好坏的标准（指导我们在目标函数集合中找到最合适的）

评价一个函数好坏的方法：

- 有正确标定的数据集时：直接用此数据输入函数中，看结果和正确值的差距
- 没有正确标定的数据集时：相似的样本应该得到相似的输出

也可以理解为给定一个衡量函数好坏的标准



找到更好的函数

> 李宏毅：根据损失函数找到目前最好的函数后，还有对其进行优化（实际上函数是有很多很多参数的，大型的模型可能有上亿的参数，在写代码过程中手动设置的参数叫“超参数”）

##### 梯度下降

##### 反向传播



生成式AI：其输出结果不再是一个简单的数字或概率，而是一个有结构的东西（图像、文字、视频等）



## 实践

### 显卡、显卡驱动、CUDA、pytorch

显卡：是硬件，也就是GPU

显卡驱动：显卡厂商提供的控制显卡的接口软件

CUDA：是 Nvidia GPU 的通用计算平台

- 我的理解：CUDA就是英伟达提供的用来控制GPU更好的并行运算的一个软件
  - （类似操作系统控制CPU进行并发）

pytorch：



> 这几个玩意儿之间是有版本依赖关系的，所以需要一步步的确定本机的版本

依赖关系：显卡 ==> 显卡驱动 ==> CUDA ==> pytorch

1. 查看显卡版本：任务管理器 -> 性能 -> GPU

![image-20230610100049851](深度学习.assets/image-20230610100049851.png)

2. 查看驱动和CUDA的版本：nvidia-smi

![](深度学习.assets/image-20230613103913764.png)

3. 安装对应版本pytorch 
    官网： https://pytorch.org/

  ![image-20230618162951661](深度学习.assets/image-20230618162951661.png)

由图可知目前官网推荐CUDA版本是11.7和11.8，而我电脑是11.6所以我决定升级以下

4. 如何升级？

首先显卡硬件是不可以改变的，那么就可以考虑升级驱动，或直接升级CUDA

- 原理就是无论是驱动或者CUDA都是向后兼容的，至少较近的几个版本兼容

英伟达官网：https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html

![image-20230613113740950](深度学习.assets/image-20230613113740950.png)

由官网可知，我机器的驱动版本支持11.8的CUDA故直接安装11.8版本CUDA即可

我选择的是conda安装，所以复制命令打开anaconda prompt进入创建好的环境中

![image-20230618163203802](深度学习.assets/image-20230618163203802.png)

anaconda会自动扫描需要下载的所有包，选择y静等下载完成

验证安装结果：pip list

![image-20230618164945180](深度学习.assets/image-20230618164945180.png)

列表中由torch表示安装完成，当然也可以调用python，输入import torch来验证，只要不报错就是安装成功

### Anaconda

一个包管理工具

其提供了一个命令行交互界面：anaconda prompt

![image-20230618160323375](深度学习.assets/image-20230618160323375.png)

#### 命令

> 【】表示括号内的内容由用户自己决定

查看当前conda版本：conda --version

查看环境：conda info --env

创建环境：conda create -n 【name】 python=【3.10】

删除环境：conda remove -n 【name】 --all

激活环境：conda activate 【name】

退出环境：conda deactivate

修改环境名称： conda create --name 【新名字】 --clone 【旧名字】

​							conda remove --name 【旧名字】 --all

### jupyter

一个web应用，简单来说和IDEA、PyCharm 类似只不过它是依赖web的应用，IDEA叫桌面应用



### pytorch

#### 常用工具

dataset类

dataloder类

##### tensorboard类

运行后要查看tensorboard，直接在终端启用conda环境，再运行下面语句：

```powershell
 tensorboard --logdir="你的logs目录"
```

运行结果会给出URL，复制到浏览器即可查看

运行结果会给出URL，复制到浏览器即可查看

一个用图表形式表现训练过程中的效果变化



##### transforms

（一个处理图像的工具库）

比如将image转换为tensor



##### 卷积

![](深度学习.assets/Conve2d输入和输出参数计算公式.png)

上图是pytorch官方文档给出的Conv2d（2维卷积）输入参数和输出结果的计算公式，<a name="Conv2D输出结果形状"> </a>

其中：$（N ， C_{in} , H_{in} , W_{in}）$的含义如下

- N：表示batchsize，即：一个批次含图片数量
- $C_{in}$：表示输入图像的通道数（channel）
- $H_{in}$：输入图像的高度
- $W_{in}$：输入图像的宽度

Output公式中dilation是空洞卷积的参数，如果不是空洞卷积则为1



```python
Conv2d(3,32,5,padding=2)
'''
	输入图像为3通道，
	输出结果为32通道
	5x5的卷积核（同图像大小一样，宽高相同简写为5，也可以用元组）
	padding为2（就是图像周围填充22像素）
	stride取默认值1
'''
Conv2d(3,32,5,1,2)	# 这样写和上面的效果等价
```



### 卷积神经网络

> CNN

CNN的灵感就是人类识别物体的过程（获取边缘等特征 ==> 抽象为图形 ==> 抽象为图像）

很棒且通俗的解释：https://easyai.tech/ai-definition/cnn/（解释CNN各个部分的功能）

#### 神经网络

> 神经网络的灵感就是学习人脑的运作过程（了解一下即可，对后续学习CNN没什么帮助）

“启发”是一个非常模棱两可的词，由一个东西启发得来的结果，可以跟这个东西毫不相干。比如我也可以说，Yin 语言的设计是受了九 yin 真经的启发 。所以

从感知器到神经网络：https://www.ruanyifeng.com/blog/2017/07/neural-network.html

**神经网络类别**

神经网络类别很多，CNN只是其中很火的一种，多用于图像处理

- 前馈神经网络（FNN）
- 递归神经网络（RNN）
- 卷积神经网络（CNN）
- 生成式对抗网络（GAN）



#### 卷积层

> 卷积层的作用：提取特征（不要问为什么能提取，总之就是可以）

简单来说就是用一个卷积核对图像进行卷积操作

卷积的计算：矩阵内积乘法（注意不是矩阵乘法）

- 矩阵内积乘法具体计算方法：两个矩阵对应位置相乘，最终结果累加



**为什么卷积可以提取特征呢？**

《线性代数的几何原理》矩阵乘法就是把一个向量变成另一个方向或长度都不相同的新向量。在这个变换过程中，原向量发生了旋转伸缩的变换。而对原向量只进行伸缩变换而无旋转操作后得到的就是特征向量，伸缩比例就是对应的特征值。

我的理解：方向相同的向量相乘得到的模长更大（也就是说卷积结果值越大，图像和卷积核越相似），而不同的卷积核可以表示不同的边缘信息，所以用卷积核进行卷积可以提取图像的边缘信息（也就是所谓的特征）

**如何确定卷积核？**

答案是：先随机取值，使用反向传播算法调整，所以每经过一轮训练都会对卷积核做修改

所以pytorch代码中Conv2D我们只需要输入卷积核大小而不需要确定卷积核具体数值。代价就是连我们自己都不知道模型选取的卷积核的含义，换言之：我们并不知道模型提取了图片中的哪些特征

可参考博客：https://www.51cto.com/article/585871.html

**卷积与滤波**

在讨论CNN的时候二者是一个意思！这两个玩意儿很像，操作也类似，但是是不一样的两个东西（大概了解一下就好，不影响学习CNN），滤波这和称呼常可以在信号处理、图像处理等领域见到，所以看到别人说滤波器（filter）可以简单理解为卷积核（问题不大）

**如何计算神经元数量？**

简单来说：用卷积核进行一次卷积就是一个神经元（就是特征图像素点个数）

- 例1：图像是1000x1000像素，而滤波器大小是10x10，padding == 0，假设滤波器没有重叠，也就是步长为10，这样隐层的神经元个数就是100x100
- 例2：图像是100x100，卷积核10x10，步长为1（stride == 1），padding == 0 （不进行填充）则神经元个数为：98*98

其实torch.nn.Conv2D的输入输出shape就是这么算的



#### 池化层

> pooling 降低图像维度（降维加速，防止过拟合）

- pool这个英语单词有“汇总”的意思，池化层也就是做了下采样

具体的效果就像给图片打上马赛克一样（降低图像维度但又保留了绝大部分的信息），常见的有最大池化、均值等算法

理解：1080P的视频很清晰人能识别画面中物体，360P有些模糊但人还是能识别画面中的物体，因此可以得出结论：适当的降低图像的清晰度不会影响画面中物体的识别，同理机器也可以。

<img src="深度学习.assets/池化层示例.png" style="zoom:60%;" />

由上面图像可以看出，经过池化操作后图像大小明显变小（降维）

**关于池化**

采样也是有讲究的，具体来说采样肯定会丢失一部分的信息，但是这些信息大部分都是对我们目标判定没有影响的（或者说丢掉的那些特征基本上都是噪声）。

平移不变性，尺度不变性，形变不变性



#### 全连接层

> FC（full connect）对CNN来说就是MLP（又叫ANN），其作用就是：依据特征对样本进行分类

ANN是其他神经网络的基础，

以CNN为例：使用卷积、池化等操作获取特征，再把特征交给FC（全连接层）进行类别概率判断。而这里的FC其实就是MLP（多层感知机）



### 多层感知机

> MLP 又叫 ANN

卷积得到的是二维特征图，全连接层就可以整合这些特征（二维图转为一维向量），全连接层的每个节点都与上一层的所有节点相连所以叫全连接层。

#### 感知机

> Perceptron，属于二元线性分类器

感知机（器）只能把数据进行二分类，而且只有样本线性可分才能正确分类。（又叫二元线性分类器）

<img src="深度学习.assets/感知器原理.png" style="zoom:20%;" />

**如何理解这个图？**

- $x_1到x_n表示n个特征，w_1到w_n$表示不同特征的权值，

- $x_0$是偏执值
  - 假设只有两个特征x和y，样本就是平面坐标上的若干点，那么这个感知器就可以理解为在二维坐标系下找到一条直线将样本点分为两类，可以看出权重决定了直线的斜率，而偏执值可以将这条直线平移
  - 我的理解：扩散一下思维，如果有n个特征输入，那么感知器就是找到一个超平面将样本在n维空间内分为两类，而偏置值可以将这个平面进行平移

感知机不能拟合XOR函数，它只能产生线性分割面！



**线性可分性**

以二维情况为例：线性可分就是能用一条直线将两类样本分开

如果没有激活函数，无论感知机有多少层都只能进行线性分类（不讲人话：无激活函数的网络无论有多少层都会退化为单层网络），可以证明：线性函数无论嵌套多少次都还是线性函数

激活函数功能和特点：[[5分钟深度学习\] #03 激活函数_哔哩哔哩_bilibili](https://www.bilibili.com/video/BV1qB4y1e7GJ) 讲的非常清晰，建议反复观看



**MLP隐藏层怎么设计？**

换句话说就是如何定义网络的形状？，超参数（隐藏层数、每层隐藏层宽度）怎么确定？

李沐：老中医手法，凭感觉，一般是由大变小



**SVM和MLP**

这两个从效果上来看差不了太多，SVM在数学特性上更漂亮，但是实际上我们用MLP更多，因为它可以很方便的转成其他网络，比如CNN，RNN

**深度学习和浅度学习**

首先，要想模拟一个函数（找到样本的分割面）我们的神经网络可以有两种选择，一种是“矮胖”（层数少但是层内的宽度很大，这就叫浅度学习），另一种是“高瘦”（层数多，但每层都比较窄，这就叫深度学习）。

两种选择可以达到差不多的模型复杂度（可理解为模型的能力大小）。但是“矮胖”不好训练（从感觉上：它更像是要一口吃成胖子，很容易overfit），“高瘦”更好训练（感觉像是循序渐进）



#### 激活函数

> Activation Funcation 功能：提供非线性

用到它的位置：输入层->隐藏层，隐藏层->隐藏层（换个说法就是：除了最后计算输出层外都要使用激活函数）

如果有位置忘记放隐藏函数了，那么这一层相当于没有（发生了层数的坍塌）

**我的理解**

比如输入是二维的（两个参数），做二分类就是找一条线把样本分开。如果没有激活函数，无论感知机有多少层都只能画出一条直线（线性分类），而引入了非线性的激活函数就能画出折线乃至曲线（毕竟折线它折的频繁一些就和曲线没什么区别嘛）

**常见函数**

**Relu**：它其实就是max(0 , x) ，它很常用，倒不是说它效果多么好，而是它计算简单（其他的函数有指数运算，更耗计算资源）

**sigmoid**：

**tanh**：

李沐：激活函数的选择远没有其它超参数对最终结果的影响大，所以随便选择就好（Relu计算简单，所以它最常用）



#### 损失函数

> 损失函数就是评估输出结果和目标结果之间的差距（loss越小越好），为更新输出提供参考依据（反向传播）



#### 反向传播



### 其它



##### 线性层

##### 正则化

##### 全局平均池化

> global average pooling，GAP



