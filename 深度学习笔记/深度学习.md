参考视频：李宏毅机器学习2023 spring

参考书籍：周志华《机器学习》



## 理论

> 机器学习就是让计算机自己找出一个函数

### 名词

泛化误差：generalization error，模型在新样本上的误差称为泛化误差

- 我的理解：泛化在这里表示该参数是模型在从未试验过的数据上运行的结果
- 泛化：以旧判新，由已知的判未知的

过拟合：overfitting

打个比方，小明

欠拟合：underfitting

参数：模型的参数（大型模型的参数能上亿）可通过优化算法来学习

超参数：定义模型结构或优化策略的参数（由程序员来设定的）

batch_size：一次处理的数据量（如果每次只处理一张图片这样会很慢，故多张图片组成一个批次，每次处理一批数据这样更快）

### 回归

### 分类

### 数学

P(A|B)：表示在B发生的条件下A发生的概率



李宏毅：机器学习分三大步

1. 设定范围（选择模型，比如CNN、Transformer等）
2. 设定标准（损失函数）
3. 达成目标（优化函数）

##### 模型

> 李宏毅：模型就是要找的函数范围（在此范围内找到合适的目标函数）

模型就是一系列候选函数的集合，比如：CNN、Transformer等



##### 损失函数

> 李宏毅：损失函数给定了衡量函数好坏的标准（指导我们在目标函数集合中找到最合适的）

评价一个函数好坏的方法：

- 有正确标定的数据集时：直接用此数据输入函数中，看结果和正确值的差距
- 没有正确标定的数据集时：相似的样本应该得到相似的输出

也可以理解为给定一个衡量函数好坏的标准



找到更好的函数

> 李宏毅：根据损失函数找到目前最好的函数后，还有对其进行优化（实际上函数是有很多很多参数的，大型的模型可能有上亿的参数，在写代码过程中手动设置的参数叫“超参数”）

##### 梯度下降

##### 反向传播



生成式AI：其输出结果不再是一个简单的数字或概率，而是一个有结构的东西（图像、文字、视频等）



## 实践

### 显卡、显卡驱动、CUDA、pytorch

显卡：是硬件，也就是GPU

显卡驱动：显卡厂商提供的控制显卡的接口软件

CUDA：是 Nvidia GPU 的通用计算平台

- 我的理解：CUDA就是英伟达提供的用来控制GPU更好的并行运算的一个软件
  - （类似操作系统控制CPU进行并发）

pytorch：



> 这几个玩意儿之间是有版本依赖关系的，所以需要一步步的确定本机的版本

依赖关系：显卡 ==> 显卡驱动 ==> CUDA ==> pytorch

1. 查看显卡版本：任务管理器 -> 性能 -> GPU

![image-20230610100049851](深度学习.assets/image-20230610100049851.png)

2. 查看驱动和CUDA的版本：nvidia-smi

![](深度学习.assets/image-20230613103913764.png)

3. 安装对应版本pytorch 
    官网： https://pytorch.org/

  ![image-20230618162951661](深度学习.assets/image-20230618162951661.png)

由图可知目前官网推荐CUDA版本是11.7和11.8，而我电脑是11.6所以我决定升级以下

4. 如何升级？

首先显卡硬件是不可以改变的，那么就可以考虑升级驱动，或直接升级CUDA

- 原理就是无论是驱动或者CUDA都是向后兼容的，至少较近的几个版本兼容

英伟达官网：https://docs.nvidia.com/cuda/cuda-toolkit-release-notes/index.html

![image-20230613113740950](深度学习.assets/image-20230613113740950.png)

由官网可知，我机器的驱动版本支持11.8的CUDA故直接安装11.8版本CUDA即可

我选择的是conda安装，所以复制命令打开anaconda prompt进入创建好的环境中

![image-20230618163203802](深度学习.assets/image-20230618163203802.png)

anaconda会自动扫描需要下载的所有包，选择y静等下载完成

验证安装结果：pip list

![image-20230618164945180](深度学习.assets/image-20230618164945180.png)

列表中由torch表示安装完成，当然也可以调用python，输入import torch来验证，只要不报错就是安装成功

### Anaconda

一个包管理工具

其提供了一个命令行交互界面：anaconda prompt

![image-20230618160323375](深度学习.assets/image-20230618160323375.png)

#### 命令

> 【】表示括号内的内容由用户自己决定

查看当前conda版本：conda --version

查看环境：conda info --env

创建环境：conda create -n 【name】 python=【3.10】

删除环境：conda remove -n 【name】 --all

激活环境：conda activate 【name】

退出环境：conda deactivate

修改环境名称： conda create --name 【新名字】 --clone 【旧名字】

​							conda remove --name 【旧名字】 --all

### jupyter

一个web应用，简单来说和IDEA、PyCharm 类似只不过它是依赖web的应用，IDEA叫桌面应用



### pytorch

#### 常用工具

dataset类

dataloder类

##### tensorboard类

运行后要查看tensorboard，直接在终端启用conda环境，再运行下面语句：

```powershell
 tensorboard --logdir="你的logs目录"
```

运行结果会给出URL，复制到浏览器即可查看

运行结果会给出URL，复制到浏览器即可查看

一个用图表形式表现训练过程中的效果变化



##### transforms

（一个处理图像的工具库）

比如将image转换为tensor



##### 卷积

![](深度学习.assets/Conve2d输入和输出参数计算公式.png)

上图是pytorch官方文档给出的Conv2d（2维卷积）输入参数和输出结果的计算公式，

其中：$（N ， C_{in} , H_{in} , W_{in}）$的含义如下

- N：表示batchsize，即：一个批次含图片数量
- $C_{in}$：表示输入图像的通道数（channel）
- $H_{in}$：输入图像的高度
- $W_{in}$：输入图像的宽度

Output公式中dilation是空洞卷积的参数，如果不是空洞卷积则为1



```python
Conv2d(3,32,5,padding=2)
'''
	输入图像为3通道，
	输出结果为32通道
	5x5的卷积核（同图像大小一样，宽高相同简写为5，也可以用元组）
	padding为2（就是图像周围填充22像素）
	stride取默认值1
'''
Conv2d(3,32,5,1,2)	# 这样写和上面的效果等价
```



### 卷积神经网络

> CNN

CNN的灵感就是人类识别物体的过程（获取边缘等特征 ==> 抽象为图形 ==> 抽象为图像）

很棒且通俗的解释：https://easyai.tech/ai-definition/cnn/（解释CNN各个部分的功能）



##### 卷积层

> 卷积层的作用：提取特征（不要问为什么能提取，总之就是可以）

简单来说就是用一个卷积核对图像进行卷积操作

卷积的计算：矩阵内积乘法（注意不是矩阵乘法）

- 矩阵内积乘法具体计算方法：两个矩阵对应位置相乘，最终结果累加



**为什么卷积可以提取特征呢？**

《线性代数的几何原理》矩阵乘法就是把一个向量变成另一个方向或长度都不相同的新向量。在这个变换过程中，原向量发生了旋转伸缩的变换。而对原向量只进行伸缩变换而无旋转操作后得到的就是特征向量，伸缩比例就是对应的特征值。

我的理解：方向相同的向量相乘得到的模长更大，而不同的卷积核可以表示不同的边缘信息，所以用卷积核进行卷积可以提取图像的边缘信息（也就是所谓的特征）

**如何确定卷积核？**

答案是：先随机取值，使用反向传播算法调整，所以每一轮得到的结果会有变化

所以pytorch代码中Conv2D我们只需要输入卷积核大小而不需要确定卷积核数值

可参考博客：https://www.51cto.com/article/585871.html



##### 池化层

> 降低图像维度（降维加速，防止过拟合）

具体的效果就像给图片打上马赛克一样（降低图像维度但又保留了绝大部分的信息），常见的有最大池化、均值等算法

1080P的视频很清晰人能识别画面中物体，360P有些模糊但人还是能识别画面中的物体，因此可以得出结论：适当的降低图像的清晰度不会影响画面中物体的识别，同理机器也可以。

<img src="深度学习.assets/池化层示例.png" style="zoom:60%;" />

由上面图像可以看出，经过池化操作后图像大小明显变小（降维）





##### 全连接层

> 全连接层的作用：分类



##### 非线性激活

##### 线性层

##### 正则化





#### 损失函数和反向传播

损失函数就是评估输出结果和目标结果之间的差距（loss越小越好），为更新输出提供参考依据（反向传播）

##### 